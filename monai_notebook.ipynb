{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MONAI Medical Imaging Notebook\n",
    "\n",
    "This notebook provides a framework for working with MONAI for medical image analysis, particularly for the intracranial aneurysm detection project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.11' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Install MONAI and dependencies\n",
    "# Uncomment the following lines if packages are not installed\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def pip_install(packages):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *packages])\n",
    "\n",
    "pip_install([\"monai\"])\n",
    "pip_install([\"nibabel\"])\n",
    "pip_install([\"pydicom\"])\n",
    "pip_install([\"torch\", \"torchvision\"])\n",
    "pip_install([\"matplotlib\"])\n",
    "pip_install([\"pandas\"])\n",
    "pip_install([\"scikit-learn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# Medical imaging libraries\n",
    "import nibabel as nib\n",
    "import pydicom\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# MONAI imports\n",
    "import monai\n",
    "from monai.config import print_config\n",
    "from monai.data import (\n",
    "    Dataset as MonaiDataset,\n",
    "    CacheDataset,\n",
    "    DataLoader as MonaiDataLoader,\n",
    "    decollate_batch\n",
    ")\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    EnsureChannelFirstd,\n",
    "    Spacingd,\n",
    "    Orientationd,\n",
    "    ScaleIntensityRanged,\n",
    "    CropForegroundd,\n",
    "    Resized,\n",
    "    RandFlipd,\n",
    "    RandRotate90d,\n",
    "    RandShiftIntensityd,\n",
    "    ToTensord,\n",
    "    AddChanneld,\n",
    "    EnsureTyped\n",
    ")\n",
    "from monai.networks.nets import (\n",
    "    DenseNet121,\n",
    "    ResNet,\n",
    "    EfficientNetBN,\n",
    "    BasicUNet\n",
    ")\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "# Print MONAI configuration\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project configuration\n",
    "CONFIG = {\n",
    "    'data_dir': '/lustre/work/sweeden/rsna-intracranial-aneurysm-detection.zip',\n",
    "    'metadata_csv': '/mnt/data/merged_medical_data_train.csv',\n",
    "    'cache_dir': './cache',\n",
    "    'output_dir': './outputs',\n",
    "    'model_dir': './models',\n",
    "    \n",
    "    # Data parameters\n",
    "    'image_size': (128, 128, 64),  # Target 3D volume size\n",
    "    'spacing': (1.0, 1.0, 1.0),    # Isotropic spacing in mm\n",
    "    \n",
    "    # Brain windowing parameters (Hounsfield Units)\n",
    "    'windows': {\n",
    "        'brain': {'center': 40, 'width': 80},\n",
    "        'subdural': {'center': 75, 'width': 215},\n",
    "        'stroke': {'center': 40, 'width': 40}\n",
    "    },\n",
    "    \n",
    "    # Training parameters\n",
    "    'batch_size': 4,\n",
    "    'num_workers': 4,\n",
    "    'epochs': 100,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1e-5,\n",
    "    'seed': 42,\n",
    "    \n",
    "    # Model parameters\n",
    "    'in_channels': 1,\n",
    "    'num_classes': 8,  # Multiple aneurysm location classes\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "# Create directories\n",
    "for dir_path in [CONFIG['cache_dir'], CONFIG['output_dir'], CONFIG['model_dir']]:\n",
    "    Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set deterministic training\n",
    "set_determinism(seed=CONFIG['seed'])\n",
    "\n",
    "print(f\"Using device: {CONFIG['device']}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_windowing(image: np.ndarray, center: float, width: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply windowing to CT image in Hounsfield Units.\n",
    "    \"\"\"\n",
    "    lower = center - width / 2\n",
    "    upper = center + width / 2\n",
    "    image = np.clip(image, lower, upper)\n",
    "    image = (image - lower) / (upper - lower)\n",
    "    return image\n",
    "\n",
    "def load_dicom_series(dicom_dir: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load a DICOM series and convert to HU.\n",
    "    \"\"\"\n",
    "    slices = []\n",
    "    for filename in sorted(glob.glob(os.path.join(dicom_dir, '*.dcm'))):\n",
    "        ds = pydicom.dcmread(filename)\n",
    "        # Convert to HU\n",
    "        pixel_array = ds.pixel_array.astype(np.float32)\n",
    "        if hasattr(ds, 'RescaleSlope') and hasattr(ds, 'RescaleIntercept'):\n",
    "            pixel_array = pixel_array * ds.RescaleSlope + ds.RescaleIntercept\n",
    "        slices.append(pixel_array)\n",
    "    \n",
    "    if slices:\n",
    "        volume = np.stack(slices, axis=-1)\n",
    "        return volume\n",
    "    return None\n",
    "\n",
    "def load_nifti_volume(nifti_path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load a NIfTI volume.\n",
    "    \"\"\"\n",
    "    nifti = nib.load(nifti_path)\n",
    "    volume = nifti.get_fdata()\n",
    "    return volume\n",
    "\n",
    "def prepare_data_list(metadata_csv: str, data_dir: str, limit: Optional[int] = None) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Prepare data list for MONAI Dataset.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(metadata_csv)\n",
    "    if limit:\n",
    "        df = df.head(limit)\n",
    "    \n",
    "    data_list = []\n",
    "    for idx, row in df.iterrows():\n",
    "        # This is a placeholder - adjust based on actual data structure\n",
    "        data_dict = {\n",
    "            'image': row.get('image_path', ''),  # Path to NIfTI or DICOM\n",
    "            'label': row.get('label', 0),\n",
    "            'series_uid': row.get('SeriesInstanceUID', ''),\n",
    "            'patient_id': row.get('PatientID', '')\n",
    "        }\n",
    "        data_list.append(data_dict)\n",
    "    \n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. MONAI Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms for training\n",
    "train_transforms = Compose([\n",
    "    LoadImaged(keys=['image']),\n",
    "    EnsureChannelFirstd(keys=['image']),\n",
    "    Spacingd(keys=['image'], pixdim=CONFIG['spacing'], mode='bilinear'),\n",
    "    Orientationd(keys=['image'], axcodes='RAS'),\n",
    "    ScaleIntensityRanged(\n",
    "        keys=['image'],\n",
    "        a_min=-1000,\n",
    "        a_max=1000,\n",
    "        b_min=0,\n",
    "        b_max=1,\n",
    "        clip=True\n",
    "    ),\n",
    "    CropForegroundd(keys=['image'], source_key='image'),\n",
    "    Resized(keys=['image'], spatial_size=CONFIG['image_size']),\n",
    "    RandFlipd(keys=['image'], prob=0.5, spatial_axis=0),\n",
    "    RandRotate90d(keys=['image'], prob=0.5, max_k=3),\n",
    "    RandShiftIntensityd(keys=['image'], offsets=0.1, prob=0.5),\n",
    "    ToTensord(keys=['image', 'label'])\n",
    "])\n",
    "\n",
    "# Define transforms for validation\n",
    "val_transforms = Compose([\n",
    "    LoadImaged(keys=['image']),\n",
    "    EnsureChannelFirstd(keys=['image']),\n",
    "    Spacingd(keys=['image'], pixdim=CONFIG['spacing'], mode='bilinear'),\n",
    "    Orientationd(keys=['image'], axcodes='RAS'),\n",
    "    ScaleIntensityRanged(\n",
    "        keys=['image'],\n",
    "        a_min=-1000,\n",
    "        a_max=1000,\n",
    "        b_min=0,\n",
    "        b_max=1,\n",
    "        clip=True\n",
    "    ),\n",
    "    CropForegroundd(keys=['image'], source_key='image'),\n",
    "    Resized(keys=['image'], spatial_size=CONFIG['image_size']),\n",
    "    ToTensord(keys=['image', 'label'])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Multi-Modal 3D CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModal3DCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-modal 3D CNN for medical image analysis.\n",
    "    Supports both NIfTI and DICOM inputs with late fusion.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=1, num_classes=8, dropout_prob=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Branch for NIfTI volumes\n",
    "        self.nifti_branch = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(2),\n",
    "            \n",
    "            nn.Conv3d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(2),\n",
    "            \n",
    "            nn.Conv3d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(2),\n",
    "            \n",
    "            nn.Conv3d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool3d(1)\n",
    "        )\n",
    "        \n",
    "        # Branch for DICOM volumes (same architecture)\n",
    "        self.dicom_branch = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(2),\n",
    "            \n",
    "            nn.Conv3d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(2),\n",
    "            \n",
    "            nn.Conv3d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(2),\n",
    "            \n",
    "            nn.Conv3d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool3d(1)\n",
    "        )\n",
    "        \n",
    "        # Fusion and classification layers\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(512, 256),  # 256 from each branch\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_prob)\n",
    "        )\n",
    "        \n",
    "        # Multi-label classification heads\n",
    "        self.location_classifier = nn.Linear(128, num_classes)  # Location classes\n",
    "        self.aneurysm_classifier = nn.Linear(128, 1)  # Any aneurysm present\n",
    "        \n",
    "    def forward(self, nifti_input=None, dicom_input=None):\n",
    "        features = []\n",
    "        \n",
    "        if nifti_input is not None:\n",
    "            nifti_feat = self.nifti_branch(nifti_input)\n",
    "            features.append(nifti_feat.view(nifti_feat.size(0), -1))\n",
    "        \n",
    "        if dicom_input is not None:\n",
    "            dicom_feat = self.dicom_branch(dicom_input)\n",
    "            features.append(dicom_feat.view(dicom_feat.size(0), -1))\n",
    "        \n",
    "        # Handle single modality\n",
    "        if len(features) == 1:\n",
    "            combined = torch.cat([features[0], torch.zeros_like(features[0])], dim=1)\n",
    "        else:\n",
    "            combined = torch.cat(features, dim=1)\n",
    "        \n",
    "        # Fusion\n",
    "        fused = self.fusion(combined)\n",
    "        \n",
    "        # Multi-label outputs\n",
    "        location_logits = self.location_classifier(fused)\n",
    "        aneurysm_logits = self.aneurysm_classifier(fused)\n",
    "        \n",
    "        return {\n",
    "            'location': torch.sigmoid(location_logits),\n",
    "            'aneurysm': torch.sigmoid(aneurysm_logits)\n",
    "        }\n",
    "\n",
    "# Initialize model\n",
    "model = MultiModal3DCNN(\n",
    "    in_channels=CONFIG['in_channels'],\n",
    "    num_classes=CONFIG['num_classes']\n",
    ").to(CONFIG['device'])\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Loss Functions and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Focal Loss for addressing class imbalance in multi-label classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = F.binary_cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        return focal_loss\n",
    "\n",
    "# Initialize loss functions\n",
    "location_loss_fn = FocalLoss(alpha=1, gamma=2)\n",
    "aneurysm_loss_fn = nn.BCELoss()\n",
    "\n",
    "# Initialize metrics\n",
    "auc_metric = ROCAUCMetric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, device):\n",
    "    \"\"\"\n",
    "    Train for one epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        images = batch['image'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(nifti_input=images)\n",
    "        \n",
    "        # Calculate losses\n",
    "        location_loss = location_loss_fn(outputs['location'], labels)\n",
    "        aneurysm_loss = aneurysm_loss_fn(\n",
    "            outputs['aneurysm'], \n",
    "            (labels.sum(dim=1, keepdim=True) > 0).float()\n",
    "        )\n",
    "        \n",
    "        total_loss = location_loss + aneurysm_loss\n",
    "        \n",
    "        # Backward pass\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += total_loss.item()\n",
    "    \n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "def validate_epoch(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Validate for one epoch.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(nifti_input=images)\n",
    "            \n",
    "            location_loss = location_loss_fn(outputs['location'], labels)\n",
    "            aneurysm_loss = aneurysm_loss_fn(\n",
    "                outputs['aneurysm'],\n",
    "                (labels.sum(dim=1, keepdim=True) > 0).float()\n",
    "            )\n",
    "            \n",
    "            total_loss = location_loss + aneurysm_loss\n",
    "            epoch_loss += total_loss.item()\n",
    "            \n",
    "            all_outputs.append(outputs['aneurysm'].cpu())\n",
    "            all_labels.append((labels.sum(dim=1, keepdim=True) > 0).float().cpu())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    all_outputs = torch.cat(all_outputs)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    auc = auc_metric(all_outputs, all_labels)\n",
    "    \n",
    "    return epoch_loss / len(dataloader), auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Main Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_training_loop():\n",
    "    \"\"\"\n",
    "    Main training pipeline.\n",
    "    \"\"\"\n",
    "    # Prepare dummy data for demonstration\n",
    "    # In practice, load from actual dataset\n",
    "    dummy_data = [\n",
    "        {\n",
    "            'image': torch.randn(1, *CONFIG['image_size']),\n",
    "            'label': torch.zeros(CONFIG['num_classes'])\n",
    "        }\n",
    "        for _ in range(20)\n",
    "    ]\n",
    "    \n",
    "    # Split data\n",
    "    train_data = dummy_data[:15]\n",
    "    val_data = dummy_data[15:]\n",
    "    \n",
    "    # Create datasets and dataloaders\n",
    "    train_dataset = MonaiDataset(data=train_data, transform=None)\n",
    "    val_dataset = MonaiDataset(data=val_data, transform=None)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    # Initialize model, optimizer, scheduler\n",
    "    model = MultiModal3DCNN(\n",
    "        in_channels=CONFIG['in_channels'],\n",
    "        num_classes=CONFIG['num_classes']\n",
    "    ).to(CONFIG['device'])\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=CONFIG['learning_rate'],\n",
    "        weight_decay=CONFIG['weight_decay']\n",
    "    )\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=CONFIG['epochs']\n",
    "    )\n",
    "    \n",
    "    # Training loop\n",
    "    best_auc = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_aucs = []\n",
    "    \n",
    "    for epoch in range(CONFIG['epochs']):\n",
    "        # Train\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, CONFIG['device'])\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_auc = validate_epoch(model, val_loader, CONFIG['device'])\n",
    "        \n",
    "        # Update scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Save metrics\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        val_aucs.append(val_auc)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_auc > best_auc:\n",
    "            best_auc = val_auc\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                os.path.join(CONFIG['model_dir'], 'best_model.pth')\n",
    "            )\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}/{CONFIG['epochs']}\")\n",
    "            print(f\"Train Loss: {train_loss:.4f}\")\n",
    "            print(f\"Val Loss: {val_loss:.4f}\")\n",
    "            print(f\"Val AUC: {val_auc:.4f}\")\n",
    "            print(\"-\" * 50)\n",
    "    \n",
    "    return train_losses, val_losses, val_aucs\n",
    "\n",
    "# Uncomment to run training\n",
    "# train_losses, val_losses, val_aucs = main_training_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(train_losses, val_losses, val_aucs):\n",
    "    \"\"\"\n",
    "    Plot training curves.\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Loss curves\n",
    "    ax1.plot(train_losses, label='Train Loss')\n",
    "    ax1.plot(val_losses, label='Val Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # AUC curve\n",
    "    ax2.plot(val_aucs, label='Val AUC')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('AUC')\n",
    "    ax2.set_title('Validation AUC')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_3d_volume(volume, slice_idx=None):\n",
    "    \"\"\"\n",
    "    Visualize 3D medical volume.\n",
    "    \"\"\"\n",
    "    if slice_idx is None:\n",
    "        slice_idx = volume.shape[2] // 2\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    \n",
    "    # Axial view\n",
    "    axes[0].imshow(volume[:, :, slice_idx], cmap='gray')\n",
    "    axes[0].set_title(f'Axial Slice {slice_idx}')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Coronal view\n",
    "    axes[1].imshow(volume[:, volume.shape[1]//2, :], cmap='gray')\n",
    "    axes[1].set_title('Coronal View')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Sagittal view\n",
    "    axes[2].imshow(volume[volume.shape[0]//2, :, :], cmap='gray')\n",
    "    axes[2].set_title('Sagittal View')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Inference and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_volume(model, volume, device='cuda'):\n",
    "    \"\"\"\n",
    "    Make prediction for a single volume.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Prepare input\n",
    "    if isinstance(volume, np.ndarray):\n",
    "        volume = torch.from_numpy(volume).float()\n",
    "    \n",
    "    if len(volume.shape) == 3:\n",
    "        volume = volume.unsqueeze(0).unsqueeze(0)  # Add batch and channel dims\n",
    "    elif len(volume.shape) == 4:\n",
    "        volume = volume.unsqueeze(0)  # Add batch dim\n",
    "    \n",
    "    volume = volume.to(device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(nifti_input=volume)\n",
    "    \n",
    "    return {\n",
    "        'location_probs': outputs['location'].cpu().numpy(),\n",
    "        'aneurysm_prob': outputs['aneurysm'].cpu().numpy()\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "# dummy_volume = torch.randn(1, *CONFIG['image_size'])\n",
    "# predictions = predict_single_volume(model, dummy_volume, CONFIG['device'])\n",
    "# print(f\"Aneurysm probability: {predictions['aneurysm_prob'][0, 0]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Model Explainability (Grad-CAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.visualize import GradCAM\n",
    "\n",
    "def generate_gradcam(model, volume, target_layer, device='cuda'):\n",
    "    \"\"\"\n",
    "    Generate Grad-CAM visualization for model predictions.\n",
    "    \"\"\"\n",
    "    # Initialize Grad-CAM\n",
    "    cam = GradCAM(nn_module=model, target_layers=target_layer)\n",
    "    \n",
    "    # Prepare input\n",
    "    if isinstance(volume, np.ndarray):\n",
    "        volume = torch.from_numpy(volume).float()\n",
    "    \n",
    "    if len(volume.shape) == 3:\n",
    "        volume = volume.unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    volume = volume.to(device)\n",
    "    \n",
    "    # Generate CAM\n",
    "    result = cam(x=volume)\n",
    "    \n",
    "    return result[0].cpu().numpy()\n",
    "\n",
    "# Example usage (requires target layer specification)\n",
    "# target_layer = 'nifti_branch.12'  # Last conv layer\n",
    "# cam_result = generate_gradcam(model, dummy_volume, target_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Export and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions_to_csv(predictions, output_path):\n",
    "    \"\"\"\n",
    "    Save predictions to CSV file.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(predictions)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Predictions saved to {output_path}\")\n",
    "\n",
    "def export_model_to_onnx(model, output_path, input_shape):\n",
    "    \"\"\"\n",
    "    Export model to ONNX format for deployment.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    dummy_input = torch.randn(1, 1, *input_shape).to(CONFIG['device'])\n",
    "    \n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        (dummy_input, None),  # Multi-modal inputs\n",
    "        output_path,\n",
    "        export_params=True,\n",
    "        opset_version=11,\n",
    "        do_constant_folding=True,\n",
    "        input_names=['nifti_input', 'dicom_input'],\n",
    "        output_names=['location', 'aneurysm'],\n",
    "        dynamic_axes={\n",
    "            'nifti_input': {0: 'batch_size'},\n",
    "            'dicom_input': {0: 'batch_size'},\n",
    "            'location': {0: 'batch_size'},\n",
    "            'aneurysm': {0: 'batch_size'}\n",
    "        }\n",
    "    )\n",
    "    print(f\"Model exported to {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "# export_model_to_onnx(model, 'model.onnx', CONFIG['image_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Summary and Next Steps\n",
    "\n",
    "This notebook provides a comprehensive framework for medical image analysis using MONAI, specifically designed for the intracranial aneurysm detection project. \n",
    "\n",
    "### Key Features:\n",
    "- Multi-modal support (NIfTI and DICOM)\n",
    "- 3D CNN architecture with late fusion\n",
    "- Multi-label classification\n",
    "- Brain-specific windowing\n",
    "- MONAI transforms and data pipeline\n",
    "- Training/validation loops\n",
    "- Model explainability (Grad-CAM)\n",
    "- Export capabilities (ONNX)\n",
    "\n",
    "### Next Steps:\n",
    "1. Connect to actual dataset (unzip and process the RSNA dataset)\n",
    "2. Implement proper data manifest creation\n",
    "3. Set up K-fold cross-validation\n",
    "4. Fine-tune hyperparameters\n",
    "5. Implement ensemble methods\n",
    "6. Add more sophisticated augmentations\n",
    "7. Deploy model for inference\n",
    "\n",
    "### Note:\n",
    "This implementation is for research purposes only and should not be used for clinical diagnosis without proper validation and regulatory approval."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
